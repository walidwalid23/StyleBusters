{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c6e7b4",
   "metadata": {},
   "source": [
    "### Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64513051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import base64\n",
    "import io\n",
    "import math \n",
    "from math import sqrt\n",
    "import argparse\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress Matplotlib warnings\n",
    "%matplotlib inline             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253a352",
   "metadata": {},
   "source": [
    "### Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f282000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "IMAGE_PATHS = 'C:\\\\Users\\\\DELL\\\\Downloads\\\\shortshirt.jpg'\n",
    "\n",
    "# PROVIDE PATH TO MODEL DIRECTORY\n",
    "PATH_TO_MODEL_DIR = 'E:\\\\Graduation Project\\\\IMPLEMENTATION\\\\tensorflow\\\\workspace\\\\training_demo\\\\exported-models\\\\my_model'\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = 'E:\\\\Graduation Project\\\\IMPLEMENTATION\\\\tensorflow\\\\workspace\\\\training_demo\\\\annotations\\\\label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dce6e",
   "metadata": {},
   "source": [
    "### Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d6b1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 14.415225505828857 seconds\n",
      "Running inference for C:\\Users\\DELL\\Downloads\\shortshirt.jpg... "
     ]
    }
   ],
   "source": [
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "\n",
    "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"\\\\saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))\n",
    "\n",
    "# LOAD LABEL MAP DATA FOR PLOTTING\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ccef5b",
   "metadata": {},
   "source": [
    "### Visualize The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(IMAGE_PATHS)\n",
    "pilImg = Image.open(IMAGE_PATHS)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "input_tensor = tf.convert_to_tensor(image)\n",
    "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# input_tensor = np.expand_dims(image_np, 0)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "\n",
    "image_with_detections = image.copy()\n",
    "\n",
    "# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_with_detections,\n",
    "      detections['detection_boxes'],\n",
    "      detections['detection_classes'],\n",
    "      detections['detection_scores'],\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=0.5,\n",
    "      agnostic_mode=False)\n",
    "\n",
    "print('Done')\n",
    "\n",
    "# DISPLAYS OUTPUT IMAGE\n",
    "cv2.imshow('final image',image_with_detections)\n",
    "#image_with_detections.show()\n",
    "\n",
    "#waits for user to press any key \n",
    "#(this is necessary to avoid Python kernel form crashing)\n",
    "cv2.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv2.destroyAllWindows() \n",
    "# CLOSES WINDOW ONCE KEY IS PRESSED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73867e",
   "metadata": {},
   "source": [
    "### Image Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac9c79",
   "metadata": {},
   "source": [
    "### Loading Pre-Trained Feature Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35ac191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "global embed\n",
    "saved_model_path = 'E:\\Graduation Project\\Datasets\\PRE TRAINED MOBILE NET'\n",
    "embed = hub.KerasLayer(saved_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b68d80",
   "metadata": {},
   "source": [
    "### Converting Images To Feature Vectors (Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0bce62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorVector(object):\n",
    "\n",
    "    def __init__(self, FileName=None):\n",
    "        self.FileName = FileName\n",
    "\n",
    "    def process(self):\n",
    "\n",
    "        img = tf.io.read_file(self.FileName)\n",
    "        img = tf.io.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize_with_pad(img, 224, 224)\n",
    "        img = tf.image.convert_image_dtype(img,tf.float32)[tf.newaxis, ...]\n",
    "        features = embed(img)\n",
    "        feature_set = np.squeeze(features)\n",
    "        return list(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecae80e",
   "metadata": {},
   "source": [
    "### class to find the similarity between two feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa8e2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Similarity:\n",
    "  def __init__(self, vector1, vector2):\n",
    "    self.vector1 = vector1\n",
    "    self.vector2 = vector2\n",
    "  def cosineSimilarity(self):\n",
    "      sum = 0\n",
    "      suma1 = 0\n",
    "      sumb1 = 0\n",
    "      for i,j in zip(self.vector1, self.vector2):\n",
    "          suma1 += i * i\n",
    "          sumb1 += j*j\n",
    "          sum += i*j\n",
    "      cosine_sim = sum / ((sqrt(suma1))*(sqrt(sumb1)))\n",
    "      return cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab8d49",
   "metadata": {},
   "source": [
    "### Path Of Main Uploaded Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3edd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_path = \"C:\\\\Users\\\\DELL\\\\Downloads\\\\shortshirt.jpg\"\n",
    "image1 = cv2.imread(img1_path, cv2.IMREAD_ANYCOLOR)  \n",
    "cv2.imshow(\"clothes\",image1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75ba90",
   "metadata": {},
   "source": [
    "### Getting feature vector of the main uploaded image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cd243d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper = TensorVector(img1_path)\n",
    "vector1 = helper.process()\n",
    "len(vector1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda5d80",
   "metadata": {},
   "source": [
    "### Looping through images in the dataset and comparing each image feature vector with the main image feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(22,24):\n",
    "  zeros_num = 6-len(str(x))\n",
    "  zeros = \"\"\n",
    "  for k in range(zeros_num):\n",
    "    zeros+=\"0\"\n",
    "  img2_path = \"E:/Graduation Project/Datasets/Deep Fashion/train/image/\"+zeros+str(x)+\".jpg\"\n",
    "  helper2 = TensorVector(img2_path)\n",
    "  vector2 = helper2.process()\n",
    "\n",
    "  print(img2_path)\n",
    "  image = cv2.imread(img2_path, cv2.IMREAD_ANYCOLOR)  \n",
    "  cosine_similarity = Similarity(vector1, vector2).cosineSimilarity()\n",
    "  print(cosine_similarity)\n",
    "\n",
    "  if cosine_similarity > 0.80:\n",
    "    print(\"Cosine Similarity of The Main Image and Image:\"+ img2_path + \" is: \"+ str(round(cosine_similarity*100))+\"%\")\n",
    "    cv2.imshow(\"Clothes\",image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607d3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
